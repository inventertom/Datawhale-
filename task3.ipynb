{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对原始数据进行特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据清洗规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入数据\n",
    "data_train = pd.read_csv('./数据集/train_data.csv')\n",
    "# data_train['Type'] = 'Train'\n",
    "data_test = pd.read_csv('./数据集/test_a.csv')\n",
    "# data_test['Type'] = 'Test'\n",
    "target_test = pd.read_csv('./数据集/评分文件/sub_a_913.csv')\n",
    "# data_all = pd.concat([data_train, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pre\n",
       "0  4808\n",
       "1  4770\n",
       "2  5701\n",
       "3  3635\n",
       "4  4387"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(data_all):\n",
    "    data_all['rentType'][data_all['rentType'] == '--'] = '未知方式'\n",
    "\n",
    "    # 将buildYear列转换为整型数据\n",
    "    buildYearmean = pd.DataFrame(data_all[data_all['buildYear'] != '暂无信息']['buildYear'].mode())\n",
    "    data_all.loc[data_all[data_all['buildYear'] == '暂无信息'].index, 'buildYear'] = buildYearmean.iloc[0, 0]\n",
    "    data_all['buildYear'] = data_all['buildYear'].astype('int')\n",
    "\n",
    "    # 处理pv和uv的空值\n",
    "    data_all['pv'].fillna(data_all['pv'].mean(), inplace=True)\n",
    "    data_all['uv'].fillna(data_all['uv'].mean(), inplace=True)\n",
    "    data_all['pv'] = data_all['pv'].astype('int')\n",
    "    data_all['uv'] = data_all['uv'].astype('int')\n",
    "\n",
    "    # 时间字段处理\n",
    "    def month(x):\n",
    "            month = int(x.split('/')[1])\n",
    "            return month\n",
    "    def day(x):\n",
    "        day = int(x.split('/')[2])\n",
    "        return day\n",
    "    data_all['month'] = data_all['tradeTime'].apply(lambda x: month(x))\n",
    "    data_all['day'] = data_all['tradeTime'].apply(lambda x: day(x))\n",
    "\n",
    "    # 删除无关字段\n",
    "    data_all.drop('city', axis=1, inplace=True)\n",
    "    data_all.drop('tradeTime', axis=1, inplace=True)\n",
    "    data_all.drop('ID', axis=1, inplace=True)\n",
    "    \n",
    "    return data_all\n",
    "    \n",
    "data_train = clean1(data_train)\n",
    "data_test = clean1(data_test)\n",
    "# # 转换object类型数据\n",
    "# columns = ['rentType','communityName','houseType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate']\n",
    "\n",
    "# for feature in columns:\n",
    "#     data_all[feature] = LabelEncoder().fit_transform(data_all[feature])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([   62,    69,   128,   131,   246,   261,   266,   297,   308,\n",
      "              313,\n",
      "            ...\n",
      "            39224, 39228, 39319, 39347, 39352, 39434, 39563, 41080, 41083,\n",
      "            41233],\n",
      "           dtype='int64', length=403)\n"
     ]
    }
   ],
   "source": [
    "# 异常值处理\n",
    "IForest = IsolationForest(contamination=0.01)\n",
    "IForest.fit(data_train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "y_pred = IForest.predict(data_train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "drop_index = data_train.loc[y_pred==-1].index\n",
    "print(drop_index)\n",
    "data_train.drop(drop_index,inplace=True)\n",
    "\n",
    "# 丢弃部分异常值\n",
    "data_train = data_train[data_train.area <= 200]\n",
    "data_train = data_train[(data_train.tradeMoney <=16000) & (data_train.tradeMoney >=700)]\n",
    "data_train.drop(data_train[(data_train['totalFloor'] == 0)].index, inplace=True)\n",
    "\n",
    "# 不同region 下的area 与TradeMoney shu\n",
    "def cleanData(data):\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['tradeMoney']<1000)&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['tradeMoney']>25000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>250)&(data['tradeMoney']<20000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>400)&(data['tradeMoney']>50000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>100)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00002') & (data['area']<100)&(data['tradeMoney']>60000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['area']<300)&(data['tradeMoney']>30000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<500)&(data['area']<50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<1500)&(data['area']>100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<2000)&(data['area']>300)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']>5000)&(data['area']<20)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['area']>600)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['tradeMoney']<1000)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']<200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']<2000)&(data['area']>180)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>50000)&(data['area']<200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['area']>200)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00007') & (data['area']>100)&(data['tradeMoney']<2500)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['area']>200)&(data['tradeMoney']>25000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['area']>400)&(data['tradeMoney']<15000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']<3000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']>7000)&(data['area']<75)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']>12500)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['area']>400)&(data['tradeMoney']>20000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008') & (data['tradeMoney']<2000)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['area']>300)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['area']>100)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00011') & (data['tradeMoney']<10000)&(data['area']>390)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00012') & (data['area']>120)&(data['tradeMoney']<5000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']<100)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']>400)&(data['tradeMoney']>50000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']>80)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['area']>300)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<1300)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<8000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<1000)&(data['area']>20)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']>25000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<20000)&(data['area']>250)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>30000)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']<50000)&(data['area']>600)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>50000)&(data['area']>350)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']>4000)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']<600)&(data['area']>100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['area']>165)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00012') & (data['tradeMoney']<800)&(data['area']<30)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00007') & (data['tradeMoney']<1100)&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['tradeMoney']>8000)&(data['area']<80)].index,inplace=True)\n",
    "    data.loc[(data['region']=='RG00002')&(data['area']>50)&(data['rentType']=='合租'),'rentType']='整租'\n",
    "    data.loc[(data['region']=='RG00014')&(data['rentType']=='合租')&(data['area']>60),'rentType']='整租'\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']>15000)&(data['area']<110)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']>20000)&(data['area']>110)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']<1500)&(data['area']<50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['rentType']=='合租')&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00015') ].index,inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "data_train = cleanData(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对data_train 数据进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将houseType转为'Room'，'Hall'，'Bath'\n",
    "def clean2(data_all):\n",
    "    \n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split(\"室\")[1].split(\"厅\")[0])\n",
    "        return Hall\n",
    "    def Bath(x):\n",
    "        Bath = int(x.split(\"室\")[1].split(\"厅\")[1].split(\"卫\")[0])\n",
    "        return Bath\n",
    "\n",
    "    data_all['Room'] = data_all['houseType'].apply(lambda x: Room(x))\n",
    "    data_all['Hall'] = data_all['houseType'].apply(lambda x: Hall(x))\n",
    "    data_all['Bath'] = data_all['houseType'].apply(lambda x: Bath(x))\n",
    "    data_all['Room_Bath'] = (data_all['Bath']+1) / (data_all['Room']+1)\n",
    "    # 填充租房类型\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['Room'] <= 1), 'rentType'] = '整租'\n",
    "    # print(data_all.loc[(data_all['rentType']=='未知方式')&(data_all['Room_Bath']>1),'rentType'])\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['Room_Bath'] > 1), 'rentType'] = '合租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['Room'] > 1) & (data_all['area'] < 50), 'rentType'] = '合租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] / data_all['Room'] < 20), 'rentType'] = '合租'\n",
    "    # data_all.loc[(data_all['rentType']=='未知方式')&(data_all['area']>60),'rentType']='合租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] <= 50) & (data_all['Room'] == 2), 'rentType'] = '合租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] > 60) & (data_all['Room'] == 2), 'rentType'] = '整租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] <= 60) & (data_all['Room'] == 3), 'rentType'] = '合租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] > 60) & (data_all['Room'] == 3), 'rentType'] = '整租'\n",
    "    data_all.loc[(data_all['rentType'] == '未知方式') & (data_all['area'] >= 100) & (data_all['Room'] > 3), 'rentType'] = '整租'\n",
    "    \n",
    "    return data_all\n",
    "data_train = clean2(data_train)\n",
    "data_test = clean2(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并部分配套设施特征\n",
    "def clean3(data_all):\n",
    "\n",
    "    data_all['trainsportNum'] = 5 * data_all['subwayStationNum'] / data_all['subwayStationNum'].mean() + data_all['busStationNum'] / \\\n",
    "                                                                                             data_all[\n",
    "                                                                                                 'busStationNum'].mean()\n",
    "    data_all['all_SchoolNum'] = 2 * data_all['interSchoolNum'] / data_all['interSchoolNum'].mean() + data_all['schoolNum'] / data_all[\n",
    "        'schoolNum'].mean() \\\n",
    "                            + data_all['privateSchoolNum'] / data_all['privateSchoolNum'].mean()\n",
    "    data_all['all_hospitalNum'] = 2 * data_all['hospitalNum'] / data_all['hospitalNum'].mean() + \\\n",
    "                              data_all['drugStoreNum'] / data_all['drugStoreNum'].mean()\n",
    "    data_all['all_mall'] = data_all['mallNum'] / data_all['mallNum'].mean() + \\\n",
    "                       data_all['superMarketNum'] / data_all['superMarketNum'].mean()\n",
    "    data_all['otherNum'] = data_all['gymNum'] / data_all['gymNum'].mean() + data_all['bankNum'] / data_all['bankNum'].mean() + \\\n",
    "                       data_all['shopNum'] / data_all['shopNum'].mean() + 2 * data_all['parkNum'] / data_all['parkNum'].mean()\n",
    "\n",
    "    data_all.drop(['subwayStationNum', 'busStationNum',\n",
    "               'interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "               'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', 'gymNum', 'bankNum', 'shopNum', 'parkNum'],\n",
    "              axis=1, inplace=True)\n",
    "    # 提升0.0005\n",
    "    \n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return data_all\n",
    "data_train = clean3(data_train)\n",
    "data_test = clean3(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all.drop('houseType', axis=1, inplace=True)\n",
    "\n",
    "data_all[\"area\"] = data_train[\"area\"].astype(int)\n",
    "\n",
    "# categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName','region', 'plate']\n",
    "categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate','cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算统计特征\n",
    "def featureCount(data):\n",
    "#     train['data_type'] = 0\n",
    "#     test['data_type'] = 1\n",
    "#     data = pd.concat([train, test], axis=0, join='outer')\n",
    "    def feature_count(data, features=[]):\n",
    "        new_feature = 'count'\n",
    "        for i in features:\n",
    "            new_feature += '_' + i\n",
    "        temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "        data = data.merge(temp, 'left', on=features)\n",
    "        return data\n",
    "\n",
    "    data = feature_count(data, ['communityName'])\n",
    "    data = feature_count(data, ['buildYear'])\n",
    "    data = feature_count(data, ['totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'newWorkers'])\n",
    "    data = feature_count(data, ['communityName', 'totalTradeMoney'])\n",
    "#     new_train = data[data['data_type'] == 0]\n",
    "#     new_test = data[data['data_type'] == 1]\n",
    "#     data.drop('data_type', axis=1, inplace=True)\n",
    "#     new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return data\n",
    "    \n",
    "data_train = featureCount(data_train)\n",
    "data_test = featureCount(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby方法生成统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby生成统计特征：mean,std等\n",
    "\n",
    "def gourpby(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    columns = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate']\n",
    "    for feature in columns:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "    temp = data.groupby('communityName')['area'].agg({'com_area_mean': 'mean', 'com_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "    \n",
    "    data['price_per_area'] = data.tradeMeanPrice / data.area * 100\n",
    "    temp = data.groupby('communityName')['price_per_area'].agg(\n",
    "        {'comm_price_mean': 'mean', 'comm_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "   \n",
    "    temp = data.groupby('plate')['price_per_area'].agg(\n",
    "        {'plate_price_mean': 'mean', 'plate_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.drop('price_per_area', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['area'].agg({'plate_area_mean': 'mean', 'plate_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    \n",
    "    temp = data.groupby(['plate'])['buildYear'].agg({'plate_year_mean': 'mean', 'plate_year_std': 'std'})\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.plate_year_mean = data.plate_year_mean.astype('int')\n",
    "    data['comm_plate_year_diff'] = data.buildYear - data.plate_year_mean\n",
    "    data.drop('plate_year_mean', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['trainsportNum'].agg('sum').reset_index(name='plate_trainsportNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['trainsportNum'].agg('sum').reset_index(name='com_trainsportNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['trainsportNum_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                           data['com_trainsportNum'], data['plate_trainsportNum']))\n",
    "    data = data.drop(['com_trainsportNum', 'plate_trainsportNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby('plate')['all_SchoolNum'].agg('sum').reset_index(name='plate_all_SchoolNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_SchoolNum'].agg('sum').reset_index(name='com_all_SchoolNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data = data.drop(['com_all_SchoolNum', 'plate_all_SchoolNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_mall'].agg('sum').reset_index(name='com_all_mall')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "\n",
    "    temp = data.groupby('plate')['otherNum'].agg('sum').reset_index(name='plate_otherNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['otherNum'].agg('sum').reset_index(name='com_otherNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['other_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                   data['com_otherNum'], data['plate_otherNum']))\n",
    "    data = data.drop(['com_otherNum', 'plate_otherNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby(['month', 'communityName']).size().reset_index(name='communityName_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'communityName'], how='left')\n",
    "    temp = data.groupby(['month', 'plate']).size().reset_index(name='plate_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'plate'], how='left')\n",
    "\n",
    "    data['sale_ratio'] = round((data.communityName_saleNum + 1) / (data.plate_saleNum + 1), 3)\n",
    "    data['sale_newworker_differ'] = 3 * data.plate_saleNum - data.newWorkers\n",
    "    data.drop(['communityName_saleNum', 'plate_saleNum'], axis=1, inplace=True)\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "\n",
    "data_train, data_test = gourpby(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聚类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#聚类\n",
    "def cluster(train,test):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    col = ['totalFloor',\n",
    "           'houseDecoration', 'communityName', 'region', 'plate', 'buildYear',\n",
    "\n",
    "           'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "           'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "\n",
    "           'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "           'newWorkers', 'residentPopulation', 'lookNum',\n",
    "           'trainsportNum',\n",
    "           'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "\n",
    "    # EM\n",
    "    gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "    data['cluster']= pd.DataFrame(gmm.fit_predict(data[col]))\n",
    "\n",
    "\n",
    "    col1 = ['totalFloor','houseDecoration', 'communityName', 'region', 'plate', 'buildYear']\n",
    "    col2 = ['tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "            'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "            'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "            'newWorkers', 'residentPopulation', 'lookNum',\n",
    "            'trainsportNum',\n",
    "            'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "    for feature1 in col1:\n",
    "        for feature2 in col2:\n",
    "        \n",
    "            temp = data.groupby(['cluster',feature1])[feature2].agg('mean').reset_index(name=feature2+'_'+feature1+'_cluster_mean')\n",
    "            temp.fillna(0, inplace=True)\n",
    "       \n",
    "            data = data.merge(temp, on=['cluster', feature1], how='left')\n",
    "    \n",
    "   \n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train, new_test\n",
    "\n",
    "data_train, data_test = cluster(data_train, data_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过大量级值取log平滑（针对线性模型有效）\n",
    "big_num_cols = ['totalTradeMoney','totalTradeArea','tradeMeanPrice','totalNewTradeMoney', 'totalNewTradeArea',\n",
    "                'tradeNewMeanPrice','remainNewNum', 'supplyNewNum', 'supplyLandArea',\n",
    "                'tradeLandArea','landTotalPrice','landMeanPrice','totalWorkers','newWorkers',\n",
    "                'residentPopulation','pv','uv']\n",
    "for col in big_num_cols:\n",
    "        data_train[col] = data_train[col].map(lambda x: np.log1p(x))\n",
    "        data_test[col] = data_test[col].map(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = data_train.drop(['houseType'],axis =1)\n",
    "data_test = data_test.drop(['houseType','tradeMoney'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tradeMoney'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tradeMoney'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-0cd60346504e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtarget_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tradeMoney'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \"\"\"\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tradeMoney'"
     ]
    }
   ],
   "source": [
    "target_train = data_train.pop('tradeMoney')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集结果： 0.7358893296396083\n",
      "测试集结果： 0.8258261575487295\n"
     ]
    }
   ],
   "source": [
    "#对比特征工程前后线性模型结果情况\n",
    "test=test.fillna(0)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(data_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(data_train)\n",
    "y_pred_test=lasso.predict(data_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相关系数法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40134, 174)\n",
      "(40134, 150)\n",
      "(2469, 150)\n",
      "训练集结果： 0.7235858160841583\n",
      "测试集结果： -0.09557046125123114\n"
     ]
    }
   ],
   "source": [
    "#相关系数法特征选择\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "print(data_train.shape)\n",
    "\n",
    "sk=SelectKBest(k=150)\n",
    "new_train=sk.fit_transform(data_train,target_train)\n",
    "print(new_train.shape)\n",
    "\n",
    "# 获取对应列索引\n",
    "select_columns=sk.get_support(indices = True)\n",
    "# print(select_columns)\n",
    "\n",
    "# 获取对应列名\n",
    "# print(test.columns[select_columns])\n",
    "select_columns_name=data_test.columns[select_columns]\n",
    "new_test=test[select_columns_name]\n",
    "print(new_test.shape)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bath', 'Hall', 'Room', 'Room_Bath', 'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'area', 'buildYear', 'communityName', 'count_buildYear', 'count_communityName', 'count_communityName_newWorkers', 'count_communityName_totalFloor', 'count_communityName_totalTradeMoney', 'count_totalFloor', 'day', 'houseDecoration', 'houseFloor', 'houseToward', 'landMeanPrice', 'landTotalPrice', 'lookNum', 'month', 'newWorkers', 'otherNum', 'plate', 'pv', 'region', 'remainNewNum', 'rentType', 'residentPopulation', 'saleSecHouseNum', 'supplyLandArea', 'supplyLandNum', 'supplyNewNum', 'totalFloor', 'totalNewTradeArea', 'totalNewTradeMoney', 'totalTradeArea', 'totalTradeMoney', 'totalWorkers', 'tradeLandArea', 'tradeLandNum', 'tradeMeanPrice', 'tradeNewMeanPrice', 'tradeNewNum', 'tradeSecNum', 'trainsportNum', 'uv', 'com_area_mean', 'com_area_std', 'comm_price_mean', 'comm_price_std', 'plate_price_mean', 'plate_price_std', 'plate_area_mean', 'plate_area_std', 'plate_year_std', 'comm_plate_year_diff', 'trainsportNum_ratio', 'com_all_mall', 'other_ratio', 'sale_ratio', 'sale_newworker_differ', 'cluster', 'tradeMeanPrice_totalFloor_cluster_mean', 'tradeSecNum_totalFloor_cluster_mean', 'totalNewTradeArea_totalFloor_cluster_mean', 'tradeNewMeanPrice_totalFloor_cluster_mean', 'tradeNewNum_totalFloor_cluster_mean', 'remainNewNum_totalFloor_cluster_mean', 'landMeanPrice_totalFloor_cluster_mean', 'totalWorkers_totalFloor_cluster_mean', 'newWorkers_totalFloor_cluster_mean', 'residentPopulation_totalFloor_cluster_mean', 'lookNum_totalFloor_cluster_mean', 'trainsportNum_totalFloor_cluster_mean', 'all_SchoolNum_totalFloor_cluster_mean', 'all_hospitalNum_totalFloor_cluster_mean', 'all_mall_totalFloor_cluster_mean', 'otherNum_totalFloor_cluster_mean', 'tradeMeanPrice_houseDecoration_cluster_mean', 'tradeSecNum_houseDecoration_cluster_mean', 'totalNewTradeArea_houseDecoration_cluster_mean', 'tradeNewMeanPrice_houseDecoration_cluster_mean', 'tradeNewNum_houseDecoration_cluster_mean', 'remainNewNum_houseDecoration_cluster_mean', 'landMeanPrice_houseDecoration_cluster_mean', 'totalWorkers_houseDecoration_cluster_mean', 'newWorkers_houseDecoration_cluster_mean', 'residentPopulation_houseDecoration_cluster_mean', 'lookNum_houseDecoration_cluster_mean', 'trainsportNum_houseDecoration_cluster_mean', 'all_SchoolNum_houseDecoration_cluster_mean', 'all_hospitalNum_houseDecoration_cluster_mean', 'all_mall_houseDecoration_cluster_mean', 'otherNum_houseDecoration_cluster_mean', 'tradeMeanPrice_communityName_cluster_mean', 'tradeSecNum_communityName_cluster_mean', 'totalNewTradeArea_communityName_cluster_mean', 'tradeNewMeanPrice_communityName_cluster_mean', 'tradeNewNum_communityName_cluster_mean', 'remainNewNum_communityName_cluster_mean', 'landMeanPrice_communityName_cluster_mean', 'totalWorkers_communityName_cluster_mean', 'newWorkers_communityName_cluster_mean', 'residentPopulation_communityName_cluster_mean', 'lookNum_communityName_cluster_mean', 'trainsportNum_communityName_cluster_mean', 'all_SchoolNum_communityName_cluster_mean', 'all_hospitalNum_communityName_cluster_mean', 'all_mall_communityName_cluster_mean', 'otherNum_communityName_cluster_mean', 'tradeMeanPrice_region_cluster_mean', 'tradeSecNum_region_cluster_mean', 'totalNewTradeArea_region_cluster_mean', 'tradeNewMeanPrice_region_cluster_mean', 'tradeNewNum_region_cluster_mean', 'remainNewNum_region_cluster_mean', 'landMeanPrice_region_cluster_mean', 'totalWorkers_region_cluster_mean', 'newWorkers_region_cluster_mean', 'residentPopulation_region_cluster_mean', 'lookNum_region_cluster_mean', 'trainsportNum_region_cluster_mean', 'all_SchoolNum_region_cluster_mean', 'all_hospitalNum_region_cluster_mean', 'all_mall_region_cluster_mean', 'otherNum_region_cluster_mean', 'tradeMeanPrice_plate_cluster_mean', 'tradeSecNum_plate_cluster_mean', 'totalNewTradeArea_plate_cluster_mean', 'tradeNewMeanPrice_plate_cluster_mean', 'tradeNewNum_plate_cluster_mean', 'remainNewNum_plate_cluster_mean', 'landMeanPrice_plate_cluster_mean', 'totalWorkers_plate_cluster_mean', 'newWorkers_plate_cluster_mean', 'residentPopulation_plate_cluster_mean', 'lookNum_plate_cluster_mean', 'trainsportNum_plate_cluster_mean', 'all_SchoolNum_plate_cluster_mean', 'all_hospitalNum_plate_cluster_mean', 'all_mall_plate_cluster_mean', 'otherNum_plate_cluster_mean', 'tradeMeanPrice_buildYear_cluster_mean', 'tradeSecNum_buildYear_cluster_mean', 'totalNewTradeArea_buildYear_cluster_mean', 'tradeNewMeanPrice_buildYear_cluster_mean', 'tradeNewNum_buildYear_cluster_mean', 'remainNewNum_buildYear_cluster_mean', 'landMeanPrice_buildYear_cluster_mean', 'newWorkers_buildYear_cluster_mean', 'lookNum_buildYear_cluster_mean', 'trainsportNum_buildYear_cluster_mean', 'all_SchoolNum_buildYear_cluster_mean', 'all_hospitalNum_buildYear_cluster_mean', 'all_mall_buildYear_cluster_mean', 'otherNum_buildYear_cluster_mean']\n",
      "训练集结果： 0.733481587401915\n",
      "测试集结果： 0.8231372123435903\n"
     ]
    }
   ],
   "source": [
    "# Wrapper\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=160)\n",
    "rfe.fit(data_train,target_train)\n",
    "\n",
    "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "                               normalize=False),\n",
    "    n_features_to_select=40, step=1, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, rfe.support_) if s]\n",
    "print(select_columns)\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded\n",
    "基于惩罚项的特征选择法  \n",
    "Lasso(l1)和Ridge(l2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 63   3 151 136 118 115  44 117   4  81 173 119  78 133 132  27 150  62\n",
      "  43  60 116 137  37 169 134   2  45  24   8 170  33 161  29 125  18  89\n",
      "  19  56 121  17  71  40  32  11  20  90  97 126  94  47 107 144  99  87\n",
      "   9 101 141  84 100  14  72  74  54 162 146  16 164 110  66 124  95  15\n",
      " 166  77  52 149 113 148  64 147 111  53 106 122  91 163 158  68 127 104\n",
      " 145 109  73 140  86 165  75 167 112  10  70 160 129  76 131 142 156 120\n",
      " 102  55 105  93  69 138 130  88  67 128 159  12 123  41  46  92  96  65\n",
      " 157  61 108 103  98  22  35  42  50 139  13  58  21  51 114  79 143  23\n",
      "  85  36 168   7  59  57  38 153   5  26  83  80  39  34  49  30  25 155\n",
      "   1 171  31   6 135 172 154 152  28  82   0  48]\n",
      "[-6.80563976e+02 -6.49654207e+02 -5.78414536e+02 -4.01981632e+02\n",
      " -3.75375567e+02 -3.64567099e+02 -3.59462077e+02 -3.45882054e+02\n",
      " -3.10160138e+02 -2.95305836e+02 -2.81415457e+02 -2.81183926e+02\n",
      " -2.51099236e+02 -2.44747486e+02 -1.46692041e+02 -1.46410263e+02\n",
      " -1.21999598e+02 -1.16784126e+02 -9.90082805e+01 -9.53580917e+01\n",
      " -9.29584419e+01 -8.97456442e+01 -8.32109487e+01 -8.05114926e+01\n",
      " -5.21309920e+01 -5.14761907e+01 -4.73571616e+01 -4.02490479e+01\n",
      " -3.87061278e+01 -2.80893402e+01 -2.73401830e+01 -1.71973368e+01\n",
      " -1.62821350e+01 -1.34921167e+01 -1.32243637e+01 -1.21116690e+01\n",
      " -1.07347390e+01 -8.34624278e+00 -7.01257141e+00 -6.71227792e+00\n",
      " -5.13904665e+00 -3.54553772e+00 -3.10030122e+00 -1.87485788e+00\n",
      " -1.82388042e+00 -1.80432929e+00 -1.57109939e+00 -1.49955732e+00\n",
      " -1.31884660e+00 -1.14898338e+00 -9.68790790e-01 -8.44477654e-01\n",
      " -6.96628943e-01 -6.14520327e-01 -5.29098406e-01 -4.08034257e-01\n",
      " -2.53916299e-01 -1.75644878e-01 -1.69501232e-01 -7.85636338e-02\n",
      " -7.46509375e-02 -3.74940221e-02 -3.25357872e-02 -3.19626041e-02\n",
      " -2.00597934e-02 -1.78855755e-02 -1.59550627e-02 -1.50174632e-02\n",
      " -1.27369779e-02 -1.15142105e-02 -7.91957878e-03 -7.33678426e-03\n",
      " -5.29198807e-03 -4.93812069e-03 -3.65960207e-03 -3.54057281e-03\n",
      " -3.51577174e-03 -3.45257010e-03 -2.61185770e-03 -1.79932451e-03\n",
      " -1.64535913e-03 -6.53175607e-04 -4.35470217e-04 -2.01656976e-06\n",
      " -1.68310199e-06 -5.87520846e-07 -4.99773575e-07 -3.72504886e-07\n",
      " -3.37578668e-07 -2.86005178e-07 -1.95611633e-07  2.63836475e-07\n",
      "  4.88367161e-07  1.31742940e-06  2.35289837e-05  3.64589295e-05\n",
      "  7.90118660e-04  1.15689009e-03  2.41154946e-03  2.90452341e-03\n",
      "  2.99289497e-03  3.62145311e-03  5.06992456e-03  6.47817361e-03\n",
      "  6.77924990e-03  1.22856406e-02  1.49859212e-02  1.71843214e-02\n",
      "  2.12574015e-02  2.19745196e-02  2.53864093e-02  4.46275582e-02\n",
      "  5.36090720e-02  7.24379708e-02  8.24808400e-02  9.58275576e-02\n",
      "  9.58504635e-02  1.46029715e-01  1.98487513e-01  1.99296725e-01\n",
      "  2.39539280e-01  2.40396507e-01  2.47973847e-01  2.62764032e-01\n",
      "  3.40300814e-01  3.45455665e-01  4.48445231e-01  7.44151029e-01\n",
      "  7.82304795e-01  1.30888520e+00  1.99018664e+00  2.22878641e+00\n",
      "  2.39800881e+00  2.61852233e+00  2.90520401e+00  3.15138794e+00\n",
      "  4.45658112e+00  4.45831293e+00  4.68499063e+00  5.70458564e+00\n",
      "  7.57340716e+00  1.57887252e+01  1.66668185e+01  2.43585822e+01\n",
      "  3.04619869e+01  3.32389850e+01  3.34405335e+01  3.70417792e+01\n",
      "  4.30128074e+01  5.24067151e+01  5.45376950e+01  6.48370789e+01\n",
      "  9.27702622e+01  1.01419954e+02  1.05933862e+02  1.10518421e+02\n",
      "  1.20110357e+02  1.27682806e+02  1.43001671e+02  1.50142119e+02\n",
      "  1.57826408e+02  2.05822162e+02  2.61767084e+02  3.33539657e+02\n",
      "  3.34212945e+02  3.56165247e+02  4.10094947e+02  4.24449428e+02\n",
      "  4.56695810e+02  4.78509560e+02  5.73329185e+02  6.80796414e+02\n",
      "  7.05826533e+02  1.07832449e+03]\n",
      "训练集结果： 0.7357931824391821\n",
      "测试集结果： 0.8257518404266342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=5)\n",
    "ridge.fit(data_train,target_train)\n",
    "\n",
    "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
    "      random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "# 特征系数排序\n",
    "coefSort = ridge.coef_.argsort()\n",
    "print(coefSort)\n",
    "\n",
    "\n",
    "# 特征系数\n",
    "featureCoefSore=ridge.coef_[coefSort]\n",
    "print(featureCoefSore)\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, featureCoefSore) if abs(s)> 0.0000005 ] \n",
    "# 选择绝对值大于0.0000005的特征\n",
    "\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于树模型的特征选择法  \n",
    "随机森林 平均不纯度减少（mean decrease impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.4518, 'area'), (0.1526, 'tradeMeanPrice_plate_cluster_mean'), (0.0605, 'tradeMeanPrice_communityName_cluster_mean'), (0.0288, 'com_area_mean'), (0.027, 'plate_area_mean'), (0.0249, 'plate_area_std'), (0.0232, 'plate_year_std'), (0.0109, 'tradeNewMeanPrice_plate_cluster_mean'), (0.0086, 'totalFloor'), (0.0086, 'comm_plate_year_diff'), (0.0073, 'tradeNewMeanPrice_communityName_cluster_mean'), (0.0068, 'plate_price_mean'), (0.0064, 'buildYear'), (0.0063, 'comm_price_mean'), (0.005, 'day'), (0.0049, 'Room'), (0.0047, 'trainsportNum_communityName_cluster_mean'), (0.0043, 'remainNewNum_communityName_cluster_mean'), (0.0042, 'tradeSecNum_communityName_cluster_mean'), (0.0042, 'sale_ratio'), (0.0039, 'com_all_mall'), (0.0038, 'other_ratio'), (0.0037, 'com_area_std'), (0.0036, 'communityName'), (0.0035, 'trainsportNum_ratio'), (0.0031, 'tradeMeanPrice'), (0.0031, 'count_communityName'), (0.0028, 'trainsportNum'), (0.0028, 'comm_price_std'), (0.0027, 'tradeNewMeanPrice'), (0.0027, 'Hall'), (0.0025, 'totalWorkers_communityName_cluster_mean'), (0.0024, 'all_hospitalNum_communityName_cluster_mean'), (0.0023, 'all_SchoolNum_communityName_cluster_mean'), (0.0022, 'count_communityName_totalFloor'), (0.0021, 'tradeMeanPrice_buildYear_cluster_mean'), (0.0021, 'totalWorkers_buildYear_cluster_mean'), (0.002, 'otherNum_communityName_cluster_mean'), (0.0019, 'totalTradeArea'), (0.0019, 'residentPopulation_communityName_cluster_mean'), (0.0018, 'totalWorkers_plate_cluster_mean'), (0.0018, 'plate_price_std'), (0.0018, 'all_mall_buildYear_cluster_mean'), (0.0018, 'all_SchoolNum_buildYear_cluster_mean'), (0.0017, 'uv'), (0.0017, 'tradeSecNum_totalFloor_cluster_mean'), (0.0017, 'tradeSecNum'), (0.0017, 'tradeNewNum_region_cluster_mean'), (0.0017, 'tradeNewMeanPrice_buildYear_cluster_mean'), (0.0017, 'remainNewNum'), (0.0017, 'houseFloor'), (0.0017, 'all_SchoolNum_totalFloor_cluster_mean'), (0.0017, 'Bath'), (0.0016, 'count_totalFloor'), (0.0016, 'count_communityName_totalTradeMoney'), (0.0016, 'all_mall_communityName_cluster_mean'), (0.0016, 'Room_Bath'), (0.0015, 'tradeSecNum_region_cluster_mean'), (0.0015, 'tradeNewMeanPrice_totalFloor_cluster_mean'), (0.0015, 'sale_newworker_differ'), (0.0015, 'residentPopulation'), (0.0015, 'houseToward'), (0.0014, 'tradeMeanPrice_totalFloor_cluster_mean'), (0.0014, 'count_buildYear'), (0.0013, 'tradeSecNum_buildYear_cluster_mean'), (0.0013, 'totalWorkers_totalFloor_cluster_mean'), (0.0013, 'totalWorkers'), (0.0013, 'totalTradeMoney'), (0.0012, 'trainsportNum_buildYear_cluster_mean'), (0.0012, 'totalNewTradeMoney_totalFloor_cluster_mean'), (0.0012, 'pv'), (0.0012, 'month'), (0.0012, 'landTotalPrice_buildYear_cluster_mean'), (0.0012, 'count_communityName_newWorkers'), (0.0011, 'tradeSecNum_plate_cluster_mean'), (0.0011, 'totalWorkers_region_cluster_mean'), (0.0011, 'residentPopulation_plate_cluster_mean'), (0.0011, 'residentPopulation_buildYear_cluster_mean'), (0.0011, 'remainNewNum_totalFloor_cluster_mean'), (0.001, 'totalNewTradeMoney_communityName_cluster_mean'), (0.001, 'all_hospitalNum_region_cluster_mean'), (0.0009, 'trainsportNum_totalFloor_cluster_mean'), (0.0009, 'tradeNewNum_communityName_cluster_mean'), (0.0009, 'tradeNewNum'), (0.0009, 'totalNewTradeMoney'), (0.0009, 'saleSecHouseNum'), (0.0009, 'landMeanPrice_buildYear_cluster_mean'), (0.0009, 'all_mall_totalFloor_cluster_mean'), (0.0009, 'all_SchoolNum_region_cluster_mean'), (0.0009, 'all_SchoolNum_plate_cluster_mean'), (0.0008, 'tradeNewNum_totalFloor_cluster_mean'), (0.0008, 'tradeMeanPrice_region_cluster_mean'), (0.0008, 'totalNewTradeMoney_buildYear_cluster_mean'), (0.0008, 'totalNewTradeArea_communityName_cluster_mean'), (0.0008, 'totalNewTradeArea'), (0.0008, 'remainNewNum_buildYear_cluster_mean'), (0.0008, 'otherNum_buildYear_cluster_mean'), (0.0008, 'landTotalPrice_totalFloor_cluster_mean'), (0.0008, 'landMeanPrice_totalFloor_cluster_mean'), (0.0008, 'all_hospitalNum_buildYear_cluster_mean'), (0.0007, 'trainsportNum_plate_cluster_mean'), (0.0007, 'residentPopulation_totalFloor_cluster_mean'), (0.0007, 'remainNewNum_plate_cluster_mean'), (0.0007, 'otherNum_totalFloor_cluster_mean'), (0.0007, 'all_hospitalNum_plate_cluster_mean'), (0.0005, 'tradeNewNum_buildYear_cluster_mean'), (0.0005, 'totalNewTradeArea_buildYear_cluster_mean'), (0.0005, 'plate'), (0.0005, 'otherNum_plate_cluster_mean'), (0.0005, 'otherNum'), (0.0005, 'lookNum_communityName_cluster_mean'), (0.0005, 'all_hospitalNum_totalFloor_cluster_mean'), (0.0004, 'trainsportNum_region_cluster_mean'), (0.0004, 'tradeSecNum_houseDecoration_cluster_mean'), (0.0004, 'totalWorkers_houseDecoration_cluster_mean'), (0.0004, 'totalNewTradeMoney_houseDecoration_cluster_mean'), (0.0004, 'totalNewTradeArea_totalFloor_cluster_mean'), (0.0004, 'supplyNewNum'), (0.0004, 'houseDecoration'), (0.0004, 'all_mall_plate_cluster_mean'), (0.0004, 'all_mall'), (0.0003, 'tradeNewNum_plate_cluster_mean'), (0.0003, 'totalNewTradeMoney_plate_cluster_mean'), (0.0003, 'rentType'), (0.0003, 'newWorkers_communityName_cluster_mean'), (0.0003, 'lookNum_buildYear_cluster_mean'), (0.0003, 'lookNum'), (0.0003, 'landTotalPrice_communityName_cluster_mean'), (0.0003, 'all_hospitalNum'), (0.0003, 'all_SchoolNum_houseDecoration_cluster_mean'), (0.0003, 'all_SchoolNum'), (0.0002, 'tradeNewMeanPrice_region_cluster_mean'), (0.0002, 'tradeNewMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'tradeMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'totalNewTradeArea_region_cluster_mean'), (0.0002, 'totalNewTradeArea_plate_cluster_mean'), (0.0002, 'remainNewNum_region_cluster_mean'), (0.0002, 'otherNum_region_cluster_mean'), (0.0002, 'newWorkers_totalFloor_cluster_mean'), (0.0002, 'newWorkers_buildYear_cluster_mean'), (0.0002, 'lookNum_totalFloor_cluster_mean'), (0.0002, 'landTotalPrice_plate_cluster_mean'), (0.0002, 'landMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'all_mall_region_cluster_mean'), (0.0002, 'all_mall_houseDecoration_cluster_mean'), (0.0001, 'trainsportNum_houseDecoration_cluster_mean'), (0.0001, 'tradeNewNum_houseDecoration_cluster_mean'), (0.0001, 'tradeLandArea'), (0.0001, 'totalNewTradeMoney_region_cluster_mean'), (0.0001, 'totalNewTradeArea_houseDecoration_cluster_mean'), (0.0001, 'supplyLandNum'), (0.0001, 'supplyLandArea'), (0.0001, 'residentPopulation_region_cluster_mean'), (0.0001, 'residentPopulation_houseDecoration_cluster_mean'), (0.0001, 'remainNewNum_houseDecoration_cluster_mean'), (0.0001, 'region'), (0.0001, 'otherNum_houseDecoration_cluster_mean'), (0.0001, 'newWorkers_plate_cluster_mean'), (0.0001, 'newWorkers'), (0.0001, 'lookNum_plate_cluster_mean'), (0.0001, 'landTotalPrice_region_cluster_mean'), (0.0001, 'landTotalPrice_houseDecoration_cluster_mean'), (0.0001, 'landMeanPrice_region_cluster_mean'), (0.0001, 'landMeanPrice_plate_cluster_mean'), (0.0001, 'landMeanPrice_communityName_cluster_mean'), (0.0001, 'landMeanPrice'), (0.0001, 'all_hospitalNum_houseDecoration_cluster_mean'), (0.0, 'tradeLandNum'), (0.0, 'newWorkers_region_cluster_mean'), (0.0, 'newWorkers_houseDecoration_cluster_mean'), (0.0, 'lookNum_region_cluster_mean'), (0.0, 'lookNum_houseDecoration_cluster_mean'), (0.0, 'landTotalPrice'), (0.0, 'cluster')]\n",
      "训练集结果： 0.7355638188774973\n",
      "测试集结果： 0.8254806070231526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()\n",
    "rf.fit(data_train,target_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), data_train.columns),\n",
    "             reverse=True))\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, rf.feature_importances_) if abs(s)> 0.00005 ] \n",
    "# 选择绝对值大于0.00005的特征\n",
    "\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
